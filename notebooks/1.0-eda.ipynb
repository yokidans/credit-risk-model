{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection System with Basel II Compliance\n",
    "**Objective**: Develop an advanced fraud detection system that:\n",
    "1. Identifies fraudulent transactions with high accuracy\n",
    "2. Quantifies risk according to Basel II regulations\n",
    "3. Provides actionable business insights\n",
    "**Methodology**:\n",
    "- Comprehensive EDA and feature engineering\n",
    "- Advanced modeling with XGBoost and Random Forest\n",
    "- Risk quantification using Basel II framework\n",
    "- Business impact analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Data Loading\n",
    "Initial setup with enhanced error handling and data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 21\n\u001b[0;32m     <a href='untitled:Untitled-1?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m     <a href='untitled:Untitled-1?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (roc_auc_score, precision_recall_curve, \n\u001b[0;32m     <a href='untitled:Untitled-1?line=19'>20</a>\u001b[0m                            average_precision_score, classification_report)\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m SMOTE\n\u001b[0;32m     <a href='untitled:Untitled-1?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mxgboost\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     <a href='untitled:Untitled-1?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m PCA\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Enhanced Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_auc_score, precision_recall_curve, \n",
    "                           average_precision_score, classification_report)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import shap\n",
    "\n",
    "# Enhanced constants and configurations\n",
    "DATA_PATH = '../data/raw/transactions.csv'\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "N_TOP_FEATURES = 15  # For feature selection\n",
    "SMOTE_SAMPLING_STRATEGY = 0.5  # For handling class imbalance\n",
    "\n",
    "# Basel II parameters\n",
    "MIN_PD = 0.0001  # Minimum probability of default\n",
    "LGD = 0.45  # Loss given default assumption\n",
    "EAD_FACTOR = 1.1  # Exposure at default multiplier\n",
    "\n",
    "# RFM analysis parameters\n",
    "RFM_WINDOW = '30D'  # Time window for RFM calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading with Enhanced Preprocessing\n",
    "- Time-based feature extraction\n",
    "- RFM (Recency, Frequency, Monetary) feature creation\n",
    "- Basel II risk metrics calculation\n",
    "- Robust outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with enhanced preprocessing...\n",
      "Error during data loading: name 'DATA_PATH' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 5\n\u001b[0;32m      <a href='untitled:Untitled-1?line=18'>19</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m      <a href='untitled:Untitled-1?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading data with enhanced preprocessing...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='untitled:Untitled-1?line=20'>21</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(DATA_PATH, parse_dates\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mTransactionStartTime\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='untitled:Untitled-1?line=22'>23</a>\u001b[0m     \u001b[39m# Add time-based features\u001b[39;00m\n\u001b[0;32m      <a href='untitled:Untitled-1?line=23'>24</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mTransactionHour\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mTransactionStartTime\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mhour\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data with enhanced error handling\n",
    "try:\n",
    "    print(\"Loading data with enhanced preprocessing...\")\n",
    "    df = pd.read_csv(DATA_PATH, parse_dates=['TransactionStartTime'])\n",
    "    \n",
    "    # Add time-based features\n",
    "    df['TransactionHour'] = df['TransactionStartTime'].dt.hour\n",
    "    df['TransactionDay'] = df['TransactionStartTime'].dt.day\n",
    "    df['TransactionDayOfWeek'] = df['TransactionStartTime'].dt.dayofweek\n",
    "    df['TransactionMonth'] = df['TransactionStartTime'].dt.month\n",
    "    \n",
    "    # Create RFM features\n",
    "    print(\"\\nCalculating RFM metrics...\")\n",
    "    current_date = df['TransactionStartTime'].max()\n",
    "    \n",
    "    # Recency: Days since last transaction\n",
    "    recency = df.groupby('CustomerId')['TransactionStartTime'].max()\n",
    "    recency = (current_date - recency).dt.days.reset_index()\n",
    "    recency.columns = ['CustomerId', 'Recency']\n",
    "    \n",
    "    # Frequency: Transaction count\n",
    "    frequency = df.groupby('CustomerId')['TransactionId'].count().reset_index()\n",
    "    frequency.columns = ['CustomerId', 'Frequency']\n",
    "    \n",
    "    # Monetary: Average transaction amount\n",
    "    monetary = df.groupby('CustomerId')['Amount'].mean().reset_index()\n",
    "    monetary.columns = ['CustomerId', 'Monetary']\n",
    "    \n",
    "    # Merge RFM features\n",
    "    rfm = recency.merge(frequency, on='CustomerId').merge(monetary, on='CustomerId')\n",
    "    df = df.merge(rfm, on='CustomerId', how='left')\n",
    "    \n",
    "    # Create Basel II relevant features\n",
    "    print(\"\\nCalculating Basel II risk metrics...\")\n",
    "    df['ExpectedLoss'] = MIN_PD * LGD * (df['Amount'] * EAD_FACTOR)\n",
    "    \n",
    "    # Enhanced data quality checks\n",
    "    print(\"\\nRunning enhanced data quality checks...\")\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(\"Warning: Missing values detected. Implementing enhanced imputation...\")\n",
    "        # For numeric columns, fill with median (more robust than mean)\n",
    "        numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "        \n",
    "        # For categorical columns, fill with mode\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # Outlier detection with enhanced methods\n",
    "    print(\"\\nRunning enhanced outlier detection...\")\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['FraudResult', 'CountryCode']:  # Skip target and constant columns\n",
    "            # Calculate robust z-scores using median and MAD\n",
    "            median = df[col].median()\n",
    "            mad = stats.median_abs_deviation(df[col], scale='normal')\n",
    "            df[f'{col}_RobustZ'] = 0.6745 * (df[col] - median) / mad  # 0.6745 scales to std normal\n",
    "            \n",
    "            # Winsorize extreme outliers (top/bottom 0.5%)\n",
    "            lower = df[col].quantile(0.005)\n",
    "            upper = df[col].quantile(0.995)\n",
    "            df[col] = np.where(df[col] < lower, lower, df[col])\n",
    "            df[col] = np.where(df[col] > upper, upper, df[col])\n",
    "    \n",
    "    print(\"\\nData loaded and preprocessed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during data loading: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "Comprehensive data overview with:\n",
    "- Data structure analysis\n",
    "- Statistical summaries\n",
    "- Fraud pattern visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 51\n\u001b[0;32m     <a href='untitled:Untitled-1?line=69'>70</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     <a href='untitled:Untitled-1?line=71'>72</a>\u001b[0m \u001b[39m# Run enhanced overview\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=72'>73</a>\u001b[0m enhanced_data_overview(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Enhanced Data Structure Overview\n",
    "def enhanced_data_overview(df):\n",
    "    \"\"\"Generate comprehensive data overview with enhanced metrics\"\"\"\n",
    "    \n",
    "    print(\"\\nEnhanced Data Structure Overview:\")\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nData Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\nEnhanced Data Types:\")\n",
    "    dtype_df = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Data Type': df.dtypes,\n",
    "        'Unique Values': df.nunique(),\n",
    "        'Missing Values': df.isnull().sum(),\n",
    "        'Missing %': (df.isnull().sum() / len(df)) * 100,\n",
    "        'Cardinality': df.nunique() / len(df),  # New: Cardinality metric\n",
    "        'Zero Values': (df == 0).sum(),  # New: Count of zeros\n",
    "        'Negative Values': (df < 0).sum()  # New: Count of negatives\n",
    "    }).reset_index(drop=True)\n",
    "    \n",
    "    display(dtype_df)\n",
    "    \n",
    "    # Enhanced descriptive statistics\n",
    "    print(\"\\nEnhanced Descriptive Statistics:\")\n",
    "    desc_stats = df.describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]).T\n",
    "    desc_stats['skewness'] = df.skew(numeric_only=True)\n",
    "    desc_stats['kurtosis'] = df.kurtosis(numeric_only=True)\n",
    "    desc_stats['IQR'] = desc_stats['75%'] - desc_stats['25%']  # New: Interquartile range\n",
    "    desc_stats['CV'] = desc_stats['std'] / desc_stats['mean']  # New: Coefficient of variation\n",
    "    \n",
    "    display(desc_stats)\n",
    "    \n",
    "    # Enhanced correlation analysis\n",
    "    print(\"\\nEnhanced Correlation Matrix (Top 10 Correlated Features with Fraud):\")\n",
    "    corr_matrix = df.corr(numeric_only=True)\n",
    "    fraud_corr = corr_matrix['FraudResult'].abs().sort_values(ascending=False)\n",
    "    display(fraud_corr.head(10))\n",
    "    \n",
    "    # Plot top correlations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(corr_matrix.loc[fraud_corr.index[:5], fraud_corr.index[:5]], \n",
    "                annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Top 5 Features Correlated with Fraud')\n",
    "    plt.show()\n",
    "\n",
    "# Run enhanced overview\n",
    "enhanced_data_overview(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 52\n\u001b[0;32m     <a href='untitled:Untitled-1?line=111'>112</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     <a href='untitled:Untitled-1?line=113'>114</a>\u001b[0m \u001b[39m# Run enhanced fraud analysis\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=114'>115</a>\u001b[0m enhanced_fraud_analysis(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Enhanced Fraud Analysis\n",
    "def enhanced_fraud_analysis(df):\n",
    "    \"\"\"Comprehensive fraud analysis with business context\"\"\"\n",
    "    \n",
    "    print(\"\\nEnhanced Fraud Analysis:\")\n",
    "    \n",
    "    # Fraud distribution with business context\n",
    "    fraud_rate = df['FraudResult'].mean()\n",
    "    print(f\"\\nOverall Fraud Rate: {fraud_rate:.4%}\")\n",
    "    print(f\"Non-Fraud Cases: {len(df[df['FraudResult']==0]):,}\")\n",
    "    print(f\"Fraud Cases: {len(df[df['FraudResult']==1]):,}\")\n",
    "    \n",
    "    # Financial impact estimation\n",
    "    fraud_amount = df[df['FraudResult']==1]['Amount'].sum()\n",
    "    avg_fraud_amount = df[df['FraudResult']==1]['Amount'].mean()\n",
    "    print(f\"\\nEstimated Total Fraud Amount: ${fraud_amount:,.2f}\")\n",
    "    print(f\"Average Fraud Amount: ${avg_fraud_amount:,.2f}\")\n",
    "    \n",
    "    # Fraud by category (business segmentation)\n",
    "    print(\"\\nFraud Rate by Product Category:\")\n",
    "    fraud_by_category = df.groupby('ProductCategory')['FraudResult'].agg(['mean', 'count'])\n",
    "    fraud_by_category.columns = ['FraudRate', 'TransactionCount']\n",
    "    fraud_by_category['FraudAmount'] = df[df['FraudResult']==1].groupby('ProductCategory')['Amount'].sum()\n",
    "    display(fraud_by_category.sort_values('FraudRate', ascending=False))\n",
    "    \n",
    "    # Temporal patterns\n",
    "    print(\"\\nFraud Rate by Hour of Day:\")\n",
    "    fraud_by_hour = df.groupby('TransactionHour')['FraudResult'].mean().reset_index()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x='TransactionHour', y='FraudResult', data=fraud_by_hour)\n",
    "    plt.title('Fraud Rate by Hour of Day')\n",
    "    plt.ylabel('Fraud Rate')\n",
    "    plt.axhline(fraud_rate, color='red', linestyle='--', label='Overall Fraud Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # RFM analysis for fraud\n",
    "    print(\"\\nRFM Analysis for Fraud Cases:\")\n",
    "    rfm_fraud = df[df['FraudResult']==1][['Recency', 'Frequency', 'Monetary']].describe().T\n",
    "    display(rfm_fraud)\n",
    "    \n",
    "    # Visualization of RFM metrics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    for i, metric in enumerate(['Recency', 'Frequency', 'Monetary']):\n",
    "        sns.boxplot(x='FraudResult', y=metric, data=df, ax=axes[i])\n",
    "        axes[i].set_title(f'{metric} Distribution by Fraud Status')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run enhanced fraud analysis\n",
    "enhanced_fraud_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "Creating advanced features for modeling:\n",
    "- Interaction features\n",
    "- Behavioral patterns\n",
    "- Rolling statistics\n",
    "- Risk flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 38\n\u001b[0;32m     <a href='untitled:Untitled-1?line=106'>107</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m     <a href='untitled:Untitled-1?line=108'>109</a>\u001b[0m \u001b[39m# Apply feature engineering\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=109'>110</a>\u001b[0m df \u001b[39m=\u001b[39m enhanced_feature_engineering(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature Engineering for Modeling\n",
    "def enhanced_feature_engineering(df):\n",
    "    \"\"\"Create advanced features for modeling\"\"\"\n",
    "    \n",
    "    print(\"\\nRunning Enhanced Feature Engineering...\")\n",
    "    \n",
    "    # Create interaction features\n",
    "    df['Amount_Recency_Interaction'] = df['Amount'] * df['Recency']\n",
    "    df['Amount_Frequency_Interaction'] = df['Amount'] * df['Frequency']\n",
    "    \n",
    "    # Create behavioral features\n",
    "    df['Amount_to_Avg_Amount_Ratio'] = df['Amount'] / df.groupby('CustomerId')['Amount'].transform('mean')\n",
    "    df['Time_Since_Last_Txn'] = df.groupby('CustomerId')['TransactionStartTime'].diff().dt.total_seconds() / 3600\n",
    "    \n",
    "    # Create rolling features (windowed statistics)\n",
    "    df = df.sort_values(['CustomerId', 'TransactionStartTime'])\n",
    "    df['Rolling_3Txn_Avg'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "    df['Rolling_24Hr_Count'] = df.groupby('CustomerId')['TransactionStartTime'].transform(\n",
    "        lambda x: x.rolling(RFM_WINDOW).count())\n",
    "    \n",
    "    # Create velocity features (change over time)\n",
    "    df['Amount_Velocity'] = df.groupby('CustomerId')['Amount'].transform(\n",
    "        lambda x: x.diff() / x.shift().where(x.shift() != 0, 1))\n",
    "    \n",
    "    # Create flags for unusual activity\n",
    "    df['Large_Transaction_Flag'] = (df['Amount'] > df['Amount'].quantile(0.95)).astype(int)\n",
    "    df['After_Hours_Flag'] = ((df['TransactionHour'] < 8) | (df['TransactionHour'] > 20)).astype(int)\n",
    "    \n",
    "    # Create Basel II relevant features\n",
    "    df['Risk_Score'] = df['ExpectedLoss'] * df['Recency']  # Simple risk score example\n",
    "    \n",
    "    print(\"Feature engineering completed. Added 10 new features.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df = enhanced_feature_engineering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Preparation\n",
    "Data preparation steps:\n",
    "- Categorical encoding\n",
    "- Train-test-validation split\n",
    "- Class imbalance handling with SMOTE\n",
    "- Feature scaling and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 65\n\u001b[0;32m     <a href='untitled:Untitled-1?line=205'>206</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m X_train_res, X_val, X_test, y_train_res, y_val, y_test, selected_features\n\u001b[0;32m     <a href='untitled:Untitled-1?line=207'>208</a>\u001b[0m \u001b[39m# Prepare model data\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=208'>209</a>\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test, selected_features \u001b[39m=\u001b[39m prepare_model_data(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Preparation\n",
    "def prepare_model_data(df):\n",
    "    \"\"\"Prepare data for modeling with enhanced methods\"\"\"\n",
    "    \n",
    "    print(\"\\nPreparing Data for Modeling...\")\n",
    "    \n",
    "    # Select features and target\n",
    "    X = df.drop(['FraudResult', 'TransactionId', 'TransactionStartTime'], axis=1)\n",
    "    y = df['FraudResult']\n",
    "    \n",
    "    # Convert categorical variables (enhanced encoding)\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if X[col].nunique() > 10:  # High cardinality - use target encoding\n",
    "            # Calculate mean fraud rate per category (smoothed)\n",
    "            fraud_rate = y.groupby(X[col]).mean()\n",
    "            counts = y.groupby(X[col]).count()\n",
    "            global_mean = y.mean()\n",
    "            smoothing = 100  # Smoothing parameter\n",
    "            \n",
    "            # Apply smoothing to avoid overfitting\n",
    "            X[col] = X[col].map((fraud_rate * counts + global_mean * smoothing) / (counts + smoothing))\n",
    "        else:  # Low cardinality - use one-hot encoding\n",
    "            X = pd.get_dummies(X, columns=[col], drop_first=True)\n",
    "    \n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Further split train into train and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=VAL_SIZE/(1-TEST_SIZE), stratify=y_train, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Handle class imbalance with SMOTE\n",
    "    print(\"\\nOriginal class distribution:\")\n",
    "    print(y_train.value_counts())\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy=SMOTE_SAMPLING_STRATEGY, random_state=RANDOM_STATE)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nResampled class distribution:\")\n",
    "    print(y_train_res.value_counts())\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_res = scaler.fit_transform(X_train_res)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(f_classif, k=N_TOP_FEATURES)\n",
    "    X_train_res = selector.fit_transform(X_train_res, y_train_res)\n",
    "    X_val = selector.transform(X_val)\n",
    "    X_test = selector.transform(X_test)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    print(\"\\nTop Selected Features:\")\n",
    "    print(selected_features)\n",
    "    \n",
    "    return X_train_res, X_val, X_test, y_train_res, y_val, y_test, selected_features\n",
    "\n",
    "# Prepare model data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, selected_features = prepare_model_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "Training and evaluating:\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "With comprehensive metrics:\n",
    "- AUC-ROC\n",
    "- Precision-Recall\n",
    "- Feature importance\n",
    "- SHAP explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 104\n\u001b[0;32m    <a href='untitled:Untitled-1?line=254'>255</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m    <a href='untitled:Untitled-1?line=256'>257</a>\u001b[0m \u001b[39m# Train and evaluate models\u001b[39;00m\n\u001b[1;32m--> <a href='untitled:Untitled-1?line=257'>258</a>\u001b[0m model_results \u001b[39m=\u001b[39m train_and_evaluate_models(X_train, X_val, X_test, y_train, y_val, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Training and Evaluation\n",
    "def train_and_evaluate_models(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \"\"\"Train and evaluate multiple models with enhanced metrics\"\"\"\n",
    "    \n",
    "    print(\"\\nTraining and Evaluating Models...\")\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "        'XGBoost': XGBClassifier(random_state=RANDOM_STATE, scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]))\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "        test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        val_ap = average_precision_score(y_val, y_val_proba)\n",
    "        test_ap = average_precision_score(y_test, y_test_proba)\n",
    "        \n",
    "        # Get optimal threshold from precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        # Apply optimal threshold to test set\n",
    "        y_test_pred = (y_test_proba >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'Validation AUC': val_auc,\n",
    "            'Test AUC': test_auc,\n",
    "            'Validation Average Precision': val_ap,\n",
    "            'Test Average Precision': test_ap,\n",
    "            'Optimal Threshold': optimal_threshold,\n",
    "            'Classification Report': report,\n",
    "            'Model': model\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{name} Performance:\")\n",
    "        print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "        print(f\"Test AUC: {test_auc:.4f}\")\n",
    "        print(f\"Validation Average Precision: {val_ap:.4f}\")\n",
    "        print(f\"Test Average Precision: {test_ap:.4f}\")\n",
    "        print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_test_pred))\n",
    "        \n",
    "        # Feature importance\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            print(\"\\nFeature Importances:\")\n",
    "            importances = pd.DataFrame({\n",
    "                'Feature': selected_features,\n",
    "                'Importance': model.feature_importances_\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            display(importances.head(10))\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x='Importance', y='Feature', data=importances.head(10))\n",
    "            plt.title(f'{name} - Top Feature Importances')\n",
    "            plt.show()\n",
    "        \n",
    "        # SHAP values for model interpretation\n",
    "        if name == 'Random Forest':  # SHAP works best with tree-based models\n",
    "            print(\"\\nCalculating SHAP values for model interpretation...\")\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "            \n",
    "            # Summary plot\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values[1], X_test, feature_names=selected_features, plot_type=\"bar\")\n",
    "            plt.title(f'{name} - SHAP Feature Importance')\n",
    "            plt.show()\n",
    "            \n",
    "            # Force plot for a specific example\n",
    "            sample_idx = np.where(y_test == 1)[0][0]  # First fraud case\n",
    "            plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[1], shap_values[1][sample_idx], \n",
    "                           X_test[sample_idx], feature_names=selected_features)\n",
    "            plt.title(f'{name} - SHAP Explanation for Fraud Case')\n",
    "            plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = train_and_evaluate_models(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basel II Capital Calculation\n",
    "Implementing Basel II framework:\n",
    "- Probability of Default (PD) estimation\n",
    "- Loss Given Default (LGD)\n",
    "- Exposure at Default (EAD)\n",
    "- Capital requirement calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 89\n\u001b[0;32m     <a href='untitled:Untitled-1?line=291'>292</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m     <a href='untitled:Untitled-1?line=293'>294</a>\u001b[0m \u001b[39m# Calculate Basel II capital\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=294'>295</a>\u001b[0m df_with_capital \u001b[39m=\u001b[39m calculate_basel_capital(df, model_results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Basel II Capital Calculation\n",
    "def calculate_basel_capital(df, model_results, selected_model='Random Forest'):\n",
    "    \"\"\"Calculate Basel II capital requirements based on model predictions\"\"\"\n",
    "    \n",
    "    print(\"\\nCalculating Basel II Capital Requirements...\")\n",
    "    \n",
    "    # Get the best model\n",
    "    model = model_results[selected_model]['Model']\n",
    "    \n",
    "    # Predict PD (Probability of Default) for all transactions\n",
    "    # Note: In practice, we'd want to predict PD at customer level over a time horizon\n",
    "    # This is a simplified transaction-level example\n",
    "    \n",
    "    # Prepare full dataset for prediction\n",
    "    X_full = df.drop(['FraudResult', 'TransactionId', 'TransactionStartTime'], axis=1)\n",
    "    \n",
    "    # Convert categorical variables (same as during training)\n",
    "    categorical_cols = X_full.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if X_full[col].nunique() > 10:  # Target encoding\n",
    "            fraud_rate = df['FraudResult'].groupby(X_full[col]).mean()\n",
    "            counts = df['FraudResult'].groupby(X_full[col]).count()\n",
    "            global_mean = df['FraudResult'].mean()\n",
    "            smoothing = 100\n",
    "            X_full[col] = X_full[col].map((fraud_rate * counts + global_mean * smoothing) / (counts + smoothing))\n",
    "        else:  # One-hot encoding\n",
    "            X_full = pd.get_dummies(X_full, columns=[col], drop_first=True)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_full_scaled = scaler.fit_transform(X_full)\n",
    "    \n",
    "    # Select features\n",
    "    selector = SelectKBest(f_classif, k=N_TOP_FEATURES)\n",
    "    X_full_scaled = selector.fit_transform(X_full_scaled, df['FraudResult'])\n",
    "    \n",
    "    # Get predictions (as proxy for PD)\n",
    "    pd_estimates = model.predict_proba(X_full_scaled)[:, 1]\n",
    "    \n",
    "    # Apply floor to PD estimates (Basel II requires minimum 0.03% for banks)\n",
    "    pd_estimates = np.maximum(pd_estimates, MIN_PD)\n",
    "    \n",
    "    # Calculate Expected Loss (EL) and Capital Requirement (K)\n",
    "    df['PD_Estimate'] = pd_estimates\n",
    "    df['LGD'] = LGD  # Using fixed LGD for simplicity\n",
    "    df['EAD'] = df['Amount'] * EAD_FACTOR  # Exposure at default\n",
    "    \n",
    "    # Expected Loss (EL) = PD × LGD × EAD\n",
    "    df['ExpectedLoss'] = df['PD_Estimate'] * df['LGD'] * df['EAD']\n",
    "    \n",
    "    # Basel II capital requirement formula (simplified)\n",
    "    # K = [LGD × N((1 - R)^-0.5 × G(PD) + (R / (1 - R))^0.5 × G(0.999)) - PD × LGD] × (1 - 1.5 × b(PD))^-1 × (1 + (M - 2.5) × b(PD))\n",
    "    # Where:\n",
    "    # R = 0.12 × (1 - exp(-50 × PD)) / (1 - exp(-50)) + 0.24 × [1 - (1 - exp(-50 × PD)) / (1 - exp(-50))]\n",
    "    # b(PD) = (0.11852 - 0.05478 × ln(PD))^2\n",
    "    # M = 1 year (maturity)\n",
    "    \n",
    "    # Simplified version using supervisory formula\n",
    "    df['R'] = 0.12 * (1 - np.exp(-50 * df['PD_Estimate'])) / (1 - np.exp(-50)) + \\\n",
    "              0.24 * (1 - (1 - np.exp(-50 * df['PD_Estimate'])) / (1 - np.exp(-50)))\n",
    "    \n",
    "    df['b'] = (0.11852 - 0.05478 * np.log(df['PD_Estimate']))**2\n",
    "    \n",
    "    # Standard normal inverse functions\n",
    "    def g(p):\n",
    "        return stats.norm.ppf(p)\n",
    "    \n",
    "    df['CapitalRequirement'] = (df['LGD'] * stats.norm.cdf(\n",
    "        (1 - df['R'])**-0.5 * g(df['PD_Estimate']) + \n",
    "        (df['R'] / (1 - df['R']))**0.5 * g(0.999)) - \n",
    "        df['PD_Estimate'] * df['LGD']) * \\\n",
    "        (1 - 1.5 * df['b'])**-1 * (1 + (1 - 2.5) * df['b'])\n",
    "    \n",
    "    # Total capital required\n",
    "    total_capital = df['CapitalRequirement'].sum()\n",
    "    total_exposure = df['EAD'].sum()\n",
    "    capital_ratio = total_capital / total_exposure\n",
    "    \n",
    "    print(\"\\nBasel II Capital Calculation Results:\")\n",
    "    print(f\"Total Exposure at Default (EAD): ${total_exposure:,.2f}\")\n",
    "    print(f\"Total Capital Required: ${total_capital:,.2f}\")\n",
    "    print(f\"Capital Ratio: {capital_ratio:.2%}\")\n",
    "    print(\"\\nNote: This is a simplified calculation. Actual Basel II implementation requires more complex modeling.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate Basel II capital\n",
    "df_with_capital = calculate_basel_capital(df, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Business Impact Analysis\n",
    "Quantifying the financial impact:\n",
    "- Fraud prevented vs. missed\n",
    "- Operational costs\n",
    "- ROI calculation\n",
    "- Customer impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 92\n\u001b[0;32m     <a href='untitled:Untitled-1?line=340'>341</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m     <a href='untitled:Untitled-1?line=341'>342</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfraud_prevented\u001b[39m\u001b[39m'\u001b[39m: fraud_prevented,\n\u001b[0;32m     <a href='untitled:Untitled-1?line=342'>343</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfraud_loss\u001b[39m\u001b[39m'\u001b[39m: fraud_loss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='untitled:Untitled-1?line=346'>347</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mongoing_roi\u001b[39m\u001b[39m'\u001b[39m: ongoing_roi\n\u001b[0;32m     <a href='untitled:Untitled-1?line=347'>348</a>\u001b[0m     }\n\u001b[0;32m     <a href='untitled:Untitled-1?line=349'>350</a>\u001b[0m \u001b[39m# Run business impact analysis\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=350'>351</a>\u001b[0m impact_results \u001b[39m=\u001b[39m business_impact_analysis(df, model_results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Business Impact Analysis\n",
    "def business_impact_analysis(df, model_results, selected_model='Random Forest'):\n",
    "    \"\"\"Analyze the business impact of implementing the fraud detection model\"\"\"\n",
    "    \n",
    "    print(\"\\nBusiness Impact Analysis:\")\n",
    "    \n",
    "    # Get model predictions and optimal threshold\n",
    "    model = model_results[selected_model]['Model']\n",
    "    threshold = model_results[selected_model]['Optimal Threshold']\n",
    "    \n",
    "    # Prepare test set for prediction\n",
    "    X = df.drop(['FraudResult', 'TransactionId', 'TransactionStartTime'], axis=1)\n",
    "    y = df['FraudResult']\n",
    "    \n",
    "    # Convert categorical variables\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if X[col].nunique() > 10:\n",
    "            fraud_rate = y.groupby(X[col]).mean()\n",
    "            counts = y.groupby(X[col]).count()\n",
    "            global_mean = y.mean()\n",
    "            smoothing = 100\n",
    "            X[col] = X[col].map((fraud_rate * counts + global_mean * smoothing) / (counts + smoothing))\n",
    "        else:\n",
    "            X = pd.get_dummies(X, columns=[col], drop_first=True)\n",
    "    \n",
    "    # Scale and select features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    selector = SelectKBest(f_classif, k=N_TOP_FEATURES)\n",
    "    X_scaled = selector.fit_transform(X_scaled, y)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    display(cm)\n",
    "    \n",
    "    # Financial impact metrics\n",
    "    fraud_caught = cm.loc[1, 1]\n",
    "    fraud_missed = cm.loc[1, 0]\n",
    "    false_positives = cm.loc[0, 1]\n",
    "    \n",
    "    avg_fraud_amount = df[df['FraudResult']==1]['Amount'].mean()\n",
    "    avg_transaction_amount = df['Amount'].mean()\n",
    "    \n",
    "    fraud_prevented = fraud_caught * avg_fraud_amount\n",
    "    fraud_loss = fraud_missed * avg_fraud_amount\n",
    "    operational_cost = false_positives * avg_transaction_amount * 0.10  # Assuming 10% of transaction amount as cost\n",
    "    \n",
    "    net_savings = fraud_prevented - fraud_loss - operational_cost\n",
    "    \n",
    "    print(\"\\nFinancial Impact Estimation:\")\n",
    "    print(f\"Fraud Prevented: ${fraud_prevented:,.2f} ({fraud_caught} transactions)\")\n",
    "    print(f\"Fraud Loss (Missed): ${fraud_loss:,.2f} ({fraud_missed} transactions)\")\n",
    "    print(f\"Operational Cost (False Positives): ${operational_cost:,.2f} ({false_positives} transactions)\")\n",
    "    print(f\"Net Savings: ${net_savings:,.2f}\")\n",
    "    \n",
    "    # ROI calculation (simplified)\n",
    "    development_cost = 50000  # Estimated model development cost\n",
    "    implementation_cost = 20000  # Estimated implementation cost\n",
    "    annual_maintenance = 10000  # Estimated annual maintenance\n",
    "    \n",
    "    first_year_roi = (net_savings - development_cost - implementation_cost) / \\\n",
    "                    (development_cost + implementation_cost)\n",
    "    ongoing_roi = (net_savings - annual_maintenance) / annual_maintenance\n",
    "    \n",
    "    print(\"\\nReturn on Investment (ROI):\")\n",
    "    print(f\"First Year ROI: {first_year_roi:.0%}\")\n",
    "    print(f\"Ongoing Annual ROI: {ongoing_roi:.0%}\")\n",
    "    \n",
    "    # Customer impact analysis\n",
    "    customers_affected = df[y_pred == 1]['CustomerId'].nunique()\n",
    "    total_customers = df['CustomerId'].nunique()\n",
    "    \n",
    "    print(\"\\nCustomer Impact:\")\n",
    "    print(f\"Customers Affected by Fraud Alerts: {customers_affected:,} ({customers_affected/total_customers:.1%})\")\n",
    "    \n",
    "    return {\n",
    "        'fraud_prevented': fraud_prevented,\n",
    "        'fraud_loss': fraud_loss,\n",
    "        'operational_cost': operational_cost,\n",
    "        'net_savings': net_savings,\n",
    "        'first_year_roi': first_year_roi,\n",
    "        'ongoing_roi': ongoing_roi\n",
    "    }\n",
    "\n",
    "# Run business impact analysis\n",
    "impact_results = business_impact_analysis(df, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deployment Recommendations\n",
    "Strategic recommendations for production:\n",
    "1. Implementation strategy\n",
    "2. Risk threshold optimization\n",
    "3. Operational integration\n",
    "4. Monitoring framework\n",
    "5. Regulatory compliance\n",
    "6. Expected benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 47\n\u001b[0;32m     <a href='untitled:Untitled-1?line=313'>314</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m- Ongoing ROI: \u001b[39m\u001b[39m{\u001b[39;00mimpact_results[\u001b[39m'\u001b[39m\u001b[39mongoing_roi\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.0%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='untitled:Untitled-1?line=315'>316</a>\u001b[0m \u001b[39m# Provide deployment recommendations\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=316'>317</a>\u001b[0m deployment_recommendations(model_results, impact_results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Deployment Recommendations\n",
    "def deployment_recommendations(model_results, impact_results):\n",
    "    \"\"\"Provide strategic recommendations for model deployment\"\"\"\n",
    "    \n",
    "    print(\"\\nModel Deployment Recommendations:\")\n",
    "    \n",
    "    # 1. Implementation Strategy\n",
    "    print(\"\\n1. Implementation Strategy:\")\n",
    "    print(\"- Phase 1: Pilot implementation with 10% of transactions to validate performance\")\n",
    "    print(\"- Phase 2: Full deployment with monitoring for concept drift\")\n",
    "    print(\"- Implement as a real-time scoring system integrated with transaction processing\")\n",
    "    \n",
    "    # 2. Risk Threshold Optimization\n",
    "    optimal_threshold = model_results['Random Forest']['Optimal Threshold']\n",
    "    print(f\"\\n2. Risk Threshold Optimization (Current: {optimal_threshold:.2f}):\")\n",
    "    print(\"- Establish threshold tuning process based on changing fraud patterns\")\n",
    "    print(\"- Create multiple thresholds for different customer segments/products\")\n",
    "    \n",
    "    # 3. Operational Integration\n",
    "    print(\"\\n3. Operational Integration:\")\n",
    "    print(\"- Integrate with case management system for fraud analysts\")\n",
    "    print(\"- Implement automated alerts for high-risk transactions\")\n",
    "    print(\"- Create escalation procedures based on risk scores\")\n",
    "    \n",
    "    # 4. Monitoring Framework\n",
    "    print(\"\\n4. Monitoring Framework:\")\n",
    "    print(\"- Track model performance metrics weekly (AUC, precision, recall)\")\n",
    "    print(\"- Monitor feature distributions for data drift\")\n",
    "    print(\"- Establish feedback loop from fraud investigation teams\")\n",
    "    \n",
    "    # 5. Regulatory Compliance\n",
    "    print(\"\\n5. Regulatory Compliance:\")\n",
    "    print(\"- Document model development process for audit purposes\")\n",
    "    print(\"- Validate model meets Basel II requirements for risk quantification\")\n",
    "    print(\"- Implement governance process for model updates\")\n",
    "    \n",
    "    # 6. Expected Benefits\n",
    "    print(\"\\n6. Expected Benefits:\")\n",
    "    print(f\"- Annual fraud prevention: ${impact_results['fraud_prevented']:,.2f}\")\n",
    "    print(f\"- Operational cost: ${impact_results['operational_cost']:,.2f}\")\n",
    "    print(f\"- Net savings: ${impact_results['net_savings']:,.2f}\")\n",
    "    print(f\"- First year ROI: {impact_results['first_year_roi']:.0%}\")\n",
    "    print(f\"- Ongoing ROI: {impact_results['ongoing_roi']:.0%}\")\n",
    "\n",
    "# Provide deployment recommendations\n",
    "deployment_recommendations(model_results, impact_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 47\n\u001b[0;32m     <a href='untitled:Untitled-1?line=352'>353</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m- Ongoing ROI: \u001b[39m\u001b[39m{\u001b[39;00mimpact_results[\u001b[39m'\u001b[39m\u001b[39mongoing_roi\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.0%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='untitled:Untitled-1?line=354'>355</a>\u001b[0m \u001b[39m# Provide deployment recommendations\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=355'>356</a>\u001b[0m deployment_recommendations(model_results, impact_results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Deployment Recommendations\n",
    "def deployment_recommendations(model_results, impact_results):\n",
    "    \"\"\"Provide strategic recommendations for model deployment\"\"\"\n",
    "    \n",
    "    print(\"\\nModel Deployment Recommendations:\")\n",
    "    \n",
    "    # 1. Implementation Strategy\n",
    "    print(\"\\n1. Implementation Strategy:\")\n",
    "    print(\"- Phase 1: Pilot implementation with 10% of transactions to validate performance\")\n",
    "    print(\"- Phase 2: Full deployment with monitoring for concept drift\")\n",
    "    print(\"- Implement as a real-time scoring system integrated with transaction processing\")\n",
    "    \n",
    "    # 2. Risk Threshold Optimization\n",
    "    optimal_threshold = model_results['Random Forest']['Optimal Threshold']\n",
    "    print(f\"\\n2. Risk Threshold Optimization (Current: {optimal_threshold:.2f}):\")\n",
    "    print(\"- Establish threshold tuning process based on changing fraud patterns\")\n",
    "    print(\"- Create multiple thresholds for different customer segments/products\")\n",
    "    \n",
    "    # 3. Operational Integration\n",
    "    print(\"\\n3. Operational Integration:\")\n",
    "    print(\"- Integrate with case management system for fraud analysts\")\n",
    "    print(\"- Implement automated alerts for high-risk transactions\")\n",
    "    print(\"- Create escalation procedures based on risk scores\")\n",
    "    \n",
    "    # 4. Monitoring Framework\n",
    "    print(\"\\n4. Monitoring Framework:\")\n",
    "    print(\"- Track model performance metrics weekly (AUC, precision, recall)\")\n",
    "    print(\"- Monitor feature distributions for data drift\")\n",
    "    print(\"- Establish feedback loop from fraud investigation teams\")\n",
    "    \n",
    "    # 5. Regulatory Compliance\n",
    "    print(\"\\n5. Regulatory Compliance:\")\n",
    "    print(\"- Document model development process for audit purposes\")\n",
    "    print(\"- Validate model meets Basel II requirements for risk quantification\")\n",
    "    print(\"- Implement governance process for model updates\")\n",
    "    \n",
    "    # 6. Expected Benefits\n",
    "    print(\"\\n6. Expected Benefits:\")\n",
    "    print(f\"- Annual fraud prevention: ${impact_results['fraud_prevented']:,.2f}\")\n",
    "    print(f\"- Operational cost: ${impact_results['operational_cost']:,.2f}\")\n",
    "    print(f\"- Net savings: ${impact_results['net_savings']:,.2f}\")\n",
    "    print(f\"- First year ROI: {impact_results['first_year_roi']:.0%}\")\n",
    "    print(f\"- Ongoing ROI: {impact_results['ongoing_roi']:.0%}\")\n",
    "\n",
    "# Provide deployment recommendations\n",
    "deployment_recommendations(model_results, impact_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 47\n\u001b[0;32m     <a href='untitled:Untitled-1?line=363'>364</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m- Ongoing ROI: \u001b[39m\u001b[39m{\u001b[39;00mimpact_results[\u001b[39m'\u001b[39m\u001b[39mongoing_roi\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.0%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='untitled:Untitled-1?line=365'>366</a>\u001b[0m \u001b[39m# Provide deployment recommendations\u001b[39;00m\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=366'>367</a>\u001b[0m deployment_recommendations(model_results, impact_results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Deployment Recommendations\n",
    "def deployment_recommendations(model_results, impact_results):\n",
    "    \"\"\"Provide strategic recommendations for model deployment\"\"\"\n",
    "    \n",
    "    print(\"\\nModel Deployment Recommendations:\")\n",
    "    \n",
    "    # 1. Implementation Strategy\n",
    "    print(\"\\n1. Implementation Strategy:\")\n",
    "    print(\"- Phase 1: Pilot implementation with 10% of transactions to validate performance\")\n",
    "    print(\"- Phase 2: Full deployment with monitoring for concept drift\")\n",
    "    print(\"- Implement as a real-time scoring system integrated with transaction processing\")\n",
    "    \n",
    "    # 2. Risk Threshold Optimization\n",
    "    optimal_threshold = model_results['Random Forest']['Optimal Threshold']\n",
    "    print(f\"\\n2. Risk Threshold Optimization (Current: {optimal_threshold:.2f}):\")\n",
    "    print(\"- Establish threshold tuning process based on changing fraud patterns\")\n",
    "    print(\"- Create multiple thresholds for different customer segments/products\")\n",
    "    \n",
    "    # 3. Operational Integration\n",
    "    print(\"\\n3. Operational Integration:\")\n",
    "    print(\"- Integrate with case management system for fraud analysts\")\n",
    "    print(\"- Implement automated alerts for high-risk transactions\")\n",
    "    print(\"- Create escalation procedures based on risk scores\")\n",
    "    \n",
    "    # 4. Monitoring Framework\n",
    "    print(\"\\n4. Monitoring Framework:\")\n",
    "    print(\"- Track model performance metrics weekly (AUC, precision, recall)\")\n",
    "    print(\"- Monitor feature distributions for data drift\")\n",
    "    print(\"- Establish feedback loop from fraud investigation teams\")\n",
    "    \n",
    "    # 5. Regulatory Compliance\n",
    "    print(\"\\n5. Regulatory Compliance:\")\n",
    "    print(\"- Document model development process for audit purposes\")\n",
    "    print(\"- Validate model meets Basel II requirements for risk quantification\")\n",
    "    print(\"- Implement governance process for model updates\")\n",
    "    \n",
    "    # 6. Expected Benefits\n",
    "    print(\"\\n6. Expected Benefits:\")\n",
    "    print(f\"- Annual fraud prevention: ${impact_results['fraud_prevented']:,.2f}\")\n",
    "    print(f\"- Operational cost: ${impact_results['operational_cost']:,.2f}\")\n",
    "    print(f\"- Net savings: ${impact_results['net_savings']:,.2f}\")\n",
    "    print(f\"- First year ROI: {impact_results['first_year_roi']:.0%}\")\n",
    "    print(f\"- Ongoing ROI: {impact_results['ongoing_roi']:.0%}\")\n",
    "\n",
    "# Provide deployment recommendations\n",
    "deployment_recommendations(model_results, impact_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection System with Basel II Compliance\n",
    "**Objective**: Develop an advanced fraud detection system that:\n",
    "1. Identifies fraudulent transactions with high accuracy\n",
    "2. Quantifies risk according to Basel II regulations\n",
    "3. Provides actionable business insights\n",
    "**Methodology**:\n",
    "- Comprehensive EDA and feature engineering\n",
    "- Advanced modeling with XGBoost and Random Forest\n",
    "- Risk quantification using Basel II framework\n",
    "- Business impact analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Data Loading\n",
    "Initial setup with enhanced error handling and data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1\u001b[0m in \u001b[0;36mline 21\n\u001b[0;32m     <a href='untitled:Untitled-1?line=403'>404</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m     <a href='untitled:Untitled-1?line=404'>405</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (roc_auc_score, precision_recall_curve, \n\u001b[0;32m     <a href='untitled:Untitled-1?line=405'>406</a>\u001b[0m                            average_precision_score, classification_report)\n\u001b[1;32m---> <a href='untitled:Untitled-1?line=406'>407</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m SMOTE\n\u001b[0;32m     <a href='untitled:Untitled-1?line=407'>408</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mxgboost\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     <a href='untitled:Untitled-1?line=408'>409</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m PCA\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Enhanced Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_auc_score, precision_recall_curve, \n",
    "                           average_precision_score, classification_report)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import shap\n",
    "\n",
    "# Enhanced constants and configurations\n",
    "DATA_PATH = '../data/raw/transactions.csv'\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "N_TOP_FEATURES = 15  # For feature selection\n",
    "SMOTE_SAMPLING_STRATEGY = 0.5  # For handling class imbalance\n",
    "\n",
    "# Basel II parameters\n",
    "MIN_PD = 0.0001  # Minimum probability of default\n",
    "LGD = 0.45  # Loss given default assumption\n",
    "EAD_FACTOR = 1.1  # Exposure at default multiplier\n",
    "\n",
    "# RFM analysis parameters\n",
    "RFM_WINDOW = '30D'  # Time window for RFM calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading with Enhanced Preprocessing\n",
    "- Time-based feature extraction\n",
    "- RFM (Recency, Frequency, Monetary) feature creation\n",
    "- Basel II risk metrics calculation\n",
    "- Robust outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Load data with enhanced error handling\n",
    "try:\n",
    "    print(\"Loading data with enhanced preprocessing...\")\n",
    "    df = pd.read_csv(DATA_PATH, parse_dates=['TransactionStartTime'])\n",
    "    \n",
    "    # Add time-based features\n",
    "    df['TransactionHour'] = df['TransactionStartTime'].dt.hour\n",
    "    df['TransactionDay'] = df['TransactionStartTime'].dt.day\n",
    "    df['TransactionDayOfWeek'] = df['TransactionStartTime'].dt.dayofweek\n",
    "    df['TransactionMonth'] = df['TransactionStartTime'].dt.month\n",
    "    \n",
    "    # Create RFM features\n",
    "    print(\"\\nCalculating RFM metrics...\")\n",
    "    current_date = df['TransactionStartTime'].max()\n",
    "    \n",
    "    # Recency: Days since last transaction\n",
    "    recency = df.groupby('CustomerId')['TransactionStartTime'].max()\n",
    "    recency = (current_date - recency).dt.days.reset_index()\n",
    "    recency.columns = ['CustomerId', 'Recency']\n",
    "    \n",
    "    # Frequency: Transaction count\n",
    "    frequency = df.groupby('CustomerId')['TransactionId'].count().reset_index()\n",
    "    frequency.columns = ['CustomerId', 'Frequency']\n",
    "    \n",
    "    # Monetary: Average transaction amount\n",
    "    monetary = df.groupby('CustomerId')['Amount'].mean().reset_index()\n",
    "    monetary.columns = ['CustomerId', 'Monetary']\n",
    "    \n",
    "    # Merge RFM features\n",
    "    rfm = recency.merge(frequency, on='CustomerId').merge(monetary, on='CustomerId')\n",
    "    df = df.merge(rfm, on='CustomerId', how='left')\n",
    "    \n",
    "    # Create Basel II relevant features\n",
    "    print(\"\\nCalculating Basel II risk metrics...\")\n",
    "    df['ExpectedLoss'] = MIN_PD * LGD * (df['Amount'] * EAD_FACTOR)\n",
    "    \n",
    "    # Enhanced data quality checks\n",
    "    print(\"\\nRunning enhanced data quality checks...\")\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(\"Warning: Missing values detected. Implementing enhanced imputation...\")\n",
    "        # For numeric columns, fill with median (more robust than mean)\n",
    "        numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "        \n",
    "        # For categorical columns, fill with mode\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # Outlier detection with enhanced methods\n",
    "    print(\"\\nRunning enhanced outlier detection...\")\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['FraudResult', 'CountryCode']:  # Skip target and constant columns\n",
    "            # Calculate robust z-scores using median and MAD\n",
    "            median = df[col].median()\n",
    "            mad = stats.median_abs_deviation(df[col], scale='normal')\n",
    "            df[f'{col}_RobustZ'] = 0.6745 * (df[col] - median) / mad  # 0.6745 scales to std normal\n",
    "            \n",
    "            # Winsorize extreme outliers (top/bottom 0.5%)\n",
    "            lower = df[col].quantile(0.005)\n",
    "            upper = df[col].quantile(0.995)\n",
    "            df[col] = np.where(df[col] < lower, lower, df[col])\n",
    "            df[col] = np.where(df[col] > upper, upper, df[col])\n",
    "    \n",
    "    print(\"\\nData loaded and preprocessed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during data loading: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "Comprehensive data overview with:\n",
    "- Data structure analysis\n",
    "- Statistical summaries\n",
    "- Fraud pattern visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Enhanced Data Structure Overview\n",
    "def enhanced_data_overview(df):\n",
    "    \"\"\"Generate comprehensive data overview with enhanced metrics\"\"\"\n",
    "    \n",
    "    print(\"\\nEnhanced Data Structure Overview:\")\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nData Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\nEnhanced Data Types:\")\n",
    "    dtype_df = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Data Type': df.dtypes,\n",
    "        'Unique Values': df.nunique(),\n",
    "        'Missing Values': df.isnull().sum(),\n",
    "        'Missing %': (df.isnull().sum() / len(df)) * 100,\n",
    "        'Cardinality': df.nunique() / len(df),  # New: Cardinality metric\n",
    "        'Zero Values': (df == 0).sum(),  # New: Count of zeros\n",
    "        'Negative Values': (df < 0).sum()  # New: Count of negatives\n",
    "    }).reset_index(drop=True)\n",
    "    \n",
    "    display(dtype_df)\n",
    "    \n",
    "    # Enhanced descriptive statistics\n",
    "    print(\"\\nEnhanced Descriptive Statistics:\")\n",
    "    desc_stats = df.describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]).T\n",
    "    desc_stats['skewness'] = df.skew(numeric_only=True)\n",
    "    desc_stats['kurtosis'] = df.kurtosis(numeric_only=True)\n",
    "    desc_stats['IQR'] = desc_stats['75%'] - desc_stats['25%']  # New: Interquartile range\n",
    "    desc_stats['CV'] = desc_stats['std'] / desc_stats['mean']  # New: Coefficient of variation\n",
    "    \n",
    "    display(desc_stats)\n",
    "    \n",
    "    # Enhanced correlation analysis\n",
    "    print(\"\\nEnhanced Correlation Matrix (Top 10 Correlated Features with Fraud):\")\n",
    "    corr_matrix = df.corr(numeric_only=True)\n",
    "    fraud_corr = corr_matrix['FraudResult'].abs().sort_values(ascending=False)\n",
    "    display(fraud_corr.head(10))\n",
    "    \n",
    "    # Plot top correlations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(corr_matrix.loc[fraud_corr.index[:5], fraud_corr.index[:5]], \n",
    "                annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Top 5 Features Correlated with Fraud')\n",
    "    plt.show()\n",
    "\n",
    "# Run enhanced overview\n",
    "enhanced_data_overview(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Enhanced Fraud Analysis\n",
    "def enhanced_fraud_analysis(df):\n",
    "    \"\"\"Comprehensive fraud analysis with business context\"\"\"\n",
    "    \n",
    "    print(\"\\nEnhanced Fraud Analysis:\")\n",
    "    \n",
    "    # Fraud distribution with business context\n",
    "    fraud_rate = df['FraudResult'].mean()\n",
    "    print(f\"\\nOverall Fraud Rate: {fraud_rate:.4%}\")\n",
    "    print(f\"Non-Fraud Cases: {len(df[df['FraudResult']==0]):,}\")\n",
    "    print(f\"Fraud Cases: {len(df[df['FraudResult']==1]):,}\")\n",
    "    \n",
    "    # Financial impact estimation\n",
    "    fraud_amount = df[df['FraudResult']==1]['Amount'].sum()\n",
    "    avg_fraud_amount = df[df['FraudResult']==1]['Amount'].mean()\n",
    "    print(f\"\\nEstimated Total Fraud Amount: ${fraud_amount:,.2f}\")\n",
    "    print(f\"Average Fraud Amount: ${avg_fraud_amount:,.2f}\")\n",
    "    \n",
    "    # Fraud by category (business segmentation)\n",
    "    print(\"\\nFraud Rate by Product Category:\")\n",
    "    fraud_by_category = df.groupby('ProductCategory')['FraudResult'].agg(['mean', 'count'])\n",
    "    fraud_by_category.columns = ['FraudRate', 'TransactionCount']\n",
    "    fraud_by_category['FraudAmount'] = df[df['FraudResult']==1].groupby('ProductCategory')['Amount'].sum()\n",
    "    display(fraud_by_category.sort_values('FraudRate', ascending=False))\n",
    "    \n",
    "    # Temporal patterns\n",
    "    print(\"\\nFraud Rate by Hour of Day:\")\n",
    "    fraud_by_hour = df.groupby('TransactionHour')['FraudResult'].mean().reset_index()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x='TransactionHour', y='FraudResult', data=fraud_by_hour)\n",
    "    plt.title('Fraud Rate by Hour of Day')\n",
    "    plt.ylabel('Fraud Rate')\n",
    "    plt.axhline(fraud_rate, color='red', linestyle='--', label='Overall Fraud Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # RFM analysis for fraud\n",
    "    print(\"\\nRFM Analysis for Fraud Cases:\")\n",
    "    rfm_fraud = df[df['FraudResult']==1][['Recency', 'Frequency', 'Monetary']].describe().T\n",
    "    display(rfm_fraud)\n",
    "    \n",
    "    # Visualization of RFM metrics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    for i, metric in enumerate(['Recency', 'Frequency', 'Monetary']):\n",
    "        sns.boxplot(x='FraudResult', y=metric, data=df, ax=axes[i])\n",
    "        axes[i].set_title(f'{metric} Distribution by Fraud Status')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run enhanced fraud analysis\n",
    "enhanced_fraud_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "Creating advanced features for modeling:\n",
    "- Interaction features\n",
    "- Behavioral patterns\n",
    "- Rolling statistics\n",
    "- Risk flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Feature Engineering for Modeling\n",
    "def enhanced_feature_engineering(df):\n",
    "    \"\"\"Create advanced features for modeling\"\"\"\n",
    "    \n",
    "    print(\"\\nRunning Enhanced Feature Engineering...\")\n",
    "    \n",
    "    # Create interaction features\n",
    "    df['Amount_Recency_Interaction'] = df['Amount'] * df['Recency']\n",
    "    df['Amount_Frequency_Interaction'] = df['Amount'] * df['Frequency']\n",
    "    \n",
    "    # Create behavioral features\n",
    "    df['Amount_to_Avg_Amount_Ratio'] = df['Amount'] / df.groupby('CustomerId')['Amount'].transform('mean')\n",
    "    df['Time_Since_Last_Txn'] = df.groupby('CustomerId')['TransactionStartTime'].diff().dt.total_seconds() / 3600\n",
    "    \n",
    "    # Create rolling features (windowed statistics)\n",
    "    df = df.sort_values(['CustomerId', 'TransactionStartTime'])\n",
    "    df['Rolling_3Txn_Avg'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "    df['Rolling_24Hr_Count'] = df.groupby('CustomerId')['TransactionStartTime'].transform(\n",
    "        lambda x: x.rolling(RFM_WINDOW).count())\n",
    "    \n",
    "    # Create velocity features (change over time)\n",
    "    df['Amount_Velocity'] = df.groupby('CustomerId')['Amount'].transform(\n",
    "        lambda x: x.diff() / x.shift().where(x.shift() != 0, 1))\n",
    "    \n",
    "    # Create flags for unusual activity\n",
    "    df['Large_Transaction_Flag'] = (df['Amount'] > df['Amount'].quantile(0.95)).astype(int)\n",
    "    df['After_Hours_Flag'] = ((df['TransactionHour'] < 8) | (df['TransactionHour'] > 20)).astype(int)\n",
    "    \n",
    "    # Create Basel II relevant features\n",
    "    df['Risk_Score'] = df['ExpectedLoss'] * df['Recency']  # Simple risk score example\n",
    "    \n",
    "    print(\"Feature engineering completed. Added 10 new features.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df = enhanced_feature_engineering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Preparation\n",
    "Data preparation steps:\n",
    "- Categorical encoding\n",
    "- Train-test-validation split\n",
    "- Class imbalance handling with SMOTE\n",
    "- Feature scaling and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Model Preparation\n",
    "def prepare_model_data(df):\n",
    "    \"\"\"Prepare data for modeling with enhanced methods\"\"\"\n",
    "    \n",
    "    print(\"\\nPreparing Data for Modeling...\")\n",
    "    \n",
    "    # Select features and target\n",
    "    X = df.drop(['FraudResult', 'TransactionId', 'TransactionStartTime'], axis=1)\n",
    "    y = df['FraudResult']\n",
    "    \n",
    "    # Convert categorical variables (enhanced encoding)\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if X[col].nunique() > 10:  # High cardinality - use target encoding\n",
    "            # Calculate mean fraud rate per category (smoothed)\n",
    "            fraud_rate = y.groupby(X[col]).mean()\n",
    "            counts = y.groupby(X[col]).count()\n",
    "            global_mean = y.mean()\n",
    "            smoothing = 100  # Smoothing parameter\n",
    "            \n",
    "            # Apply smoothing to avoid overfitting\n",
    "            X[col] = X[col].map((fraud_rate * counts + global_mean * smoothing) / (counts + smoothing))\n",
    "        else:  # Low cardinality - use one-hot encoding\n",
    "            X = pd.get_dummies(X, columns=[col], drop_first=True)\n",
    "    \n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Further split train into train and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=VAL_SIZE/(1-TEST_SIZE), stratify=y_train, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Handle class imbalance with SMOTE\n",
    "    print(\"\\nOriginal class distribution:\")\n",
    "    print(y_train.value_counts())\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy=SMOTE_SAMPLING_STRATEGY, random_state=RANDOM_STATE)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nResampled class distribution:\")\n",
    "    print(y_train_res.value_counts())\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_res = scaler.fit_transform(X_train_res)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(f_classif, k=N_TOP_FEATURES)\n",
    "    X_train_res = selector.fit_transform(X_train_res, y_train_res)\n",
    "    X_val = selector.transform(X_val)\n",
    "    X_test = selector.transform(X_test)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    print(\"\\nTop Selected Features:\")\n",
    "    print(selected_features)\n",
    "    \n",
    "    return X_train_res, X_val, X_test, y_train_res, y_val, y_test, selected_features\n",
    "\n",
    "# Prepare model data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, selected_features = prepare_model_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "Training and evaluating:\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "With comprehensive metrics:\n",
    "- AUC-ROC\n",
    "- Precision-Recall\n",
    "- Feature importance\n",
    "- SHAP explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Model Training and Evaluation\n",
    "def train_and_evaluate_models(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \"\"\"Train and evaluate multiple models with enhanced metrics\"\"\"\n",
    "    \n",
    "    print(\"\\nTraining and Evaluating Models...\")\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "        'XGBoost': XGBClassifier(random_state=RANDOM_STATE, scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]))\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "        test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        val_ap = average_precision_score(y_val, y_val_proba)\n",
    "        test_ap = average_precision_score(y_test, y_test_proba)\n",
    "        \n",
    "        # Get optimal threshold from precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        # Apply optimal threshold to test set\n",
    "        y_test_pred = (y_test_proba >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'Validation AUC': val_auc,\n",
    "            'Test AUC': test_auc,\n",
    "            'Validation Average Precision': val_ap,\n",
    "            'Test Average Precision': test_ap,\n",
    "            'Optimal Threshold': optimal_threshold,\n",
    "            'Classification Report': report,\n",
    "            'Model': model\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{name} Performance:\")\n",
    "        print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "        print(f\"Test AUC: {test_auc:.4f}\")\n",
    "        print(f\"Validation Average Precision: {val_ap:.4f}\")\n",
    "        print(f\"Test Average Precision: {test_ap:.4f}\")\n",
    "        print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_test_pred))\n",
    "        \n",
    "        # Feature importance\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            print(\"\\nFeature Importances:\")\n",
    "            importances = pd.DataFrame({\n",
    "                'Feature': selected_features,\n",
    "                'Importance': model.feature_importances_\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            display(importances.head(10))\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x='Importance', y='Feature', data=importances.head(10))\n",
    "            plt.title(f'{name} - Top Feature Importances')\n",
    "            plt.show()\n",
    "        \n",
    "        # SHAP values for model interpretation\n",
    "        if name == 'Random Forest':  # SHAP works best with tree-based models\n",
    "            print(\"\\nCalculating SHAP values for model interpretation...\")\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "            \n",
    "            # Summary plot\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values[1], X_test, feature_names=selected_features, plot_type=\"bar\")\n",
    "            plt.title(f'{name} - SHAP Feature Importance')\n",
    "            plt.show()\n",
    "            \n",
    "            # Force plot for a specific example\n",
    "            sample_idx = np.where(y_test == 1)[0][0]  # First fraud case\n",
    "            plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[1], shap_values[1][sample_idx], \n",
    "                           X_test[sample_idx], feature_names=selected_features)\n",
    "            plt.title(f'{name} - SHAP Explanation for Fraud Case')\n",
    "            plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = train_and_evaluate_models(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basel II Capital Calculation\n",
    "Implementing Basel II framework:\n",
    "- Probability of Default (PD) estimation\n",
    "- Loss Given Default (LGD)\n",
    "- Exposure at Default (EAD)\n",
    "- Capital requirement calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Basel II Capital Calculation\n",
    "def calculate_basel_capital(df, model_results, selected_model='Random Forest'):\n",
    "    \"\"\"Calculate Basel II capital requirements based on model predictions\"\"\"\n",
    "    \n",
    "    print(\"\\nCalculating Basel II Capital Requirements...\")\n",
    "    \n",
    "    # Get the best model\n",
    "    model = model_results[selected_model]['Model']\n",
    "    \n",
    "    # Predict PD (Probability of Default) for all transactions\n",
    "    # Note: In practice, we'd want to predict PD at customer level over a time horizon\n",
    "    # This is a simplified transaction-level example\n",
    "    \n",
    "    # Prepare full dataset for prediction\n",
    "    X_full = df.drop(['FraudResult', 'TransactionId', 'TransactionStartTime'], axis=1)\n",
    "    \n",
    "    # Convert categorical variables (same as during training)\n",
    "    categorical_cols = X_full.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if X_full[col].nunique() > 10:  # Target encoding\n",
    "            fraud_rate = df['FraudResult'].groupby(X_full[col]).mean()\n",
    "            counts = df['FraudResult'].groupby(X_full[col]).count()\n",
    "            global_mean = df['FraudResult'].mean()\n",
    "            smoothing = 100\n",
    "            X_full[col] = X_full[col].map((fraud_rate * counts + global_mean * smoothing) / (counts + smoothing))\n",
    "        else:  # One-hot encoding\n",
    "            X_full = pd.get_dummies(X_full, columns=[col], drop_first=True)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_full_scaled = scaler.fit_transform(X_full)\n",
    "    \n",
    "    # Select features\n",
    "    selector = SelectKBest(f_classif, k=N_TOP_FEATURES)\n",
    "    X_full_scaled = selector.fit_transform(X_full_scaled, df['FraudResult'])\n",
    "    \n",
    "    # Get predictions (as proxy for PD)\n",
    "    pd_estimates = model.predict_proba(X_full_scaled)[:, 1]\n",
    "    \n",
    "    # Apply floor to PD estimates (Basel II requires minimum 0.03% for banks)\n",
    "    pd_estimates = np.maximum(pd_estimates, MIN_PD)\n",
    "    \n",
    "    # Calculate Expected Loss (EL) and Capital Requirement (K)\n",
    "    df['PD_Estimate'] = pd_estimates\n",
    "    df['LGD'] = LGD  # Using fixed LGD for simplicity\n",
    "    df['EAD'] = df['Amount'] * EAD_FACTOR  # Exposure at default\n",
    "    \n",
    "    # Expected Loss (EL) = PD × LGD × EAD\n",
    "    df['ExpectedLoss'] = df['PD_Estimate'] * df['LGD'] * df['EAD']\n",
    "    \n",
    "    # Basel II capital requirement formula (simplified)\n",
    "    # K = [LGD × N((1 - R)^-0.5 × G(PD) + (R / (1 - R))^0.5 × G(0.999)) - PD × LGD] × (1 - 1.5 × b(PD))^-1 × (1 + (M - 2.5) × b(PD))\n",
    "    # Where:\n",
    "    # R = 0.12 × (1 - exp(-50 × PD)) / (1 - exp(-50)) + 0.24 × [1 - (1 - exp(-50 × PD)) / (1 - exp(-50))]\n",
    "    # b(PD) = (0.11852 - 0.05478 × ln(PD))^2\n",
    "    # M = 1 year (maturity)\n",
    "    \n",
    "    # Simplified version using supervisory formula\n",
    "    df['R'] = 0.12 * (1 - np.exp(-50 * df['PD_Estimate'])) / (1 - np.exp(-50)) + \\\n",
    "              0.24 * (1 - (1 - np.exp(-50 * df['PD_Estimate'])) / (1 - np.exp(-50)))\n",
    "    \n",
    "    df['b'] = (0.11852 - 0.05478 * np.log(df['PD_Estimate']))**2\n",
    "    \n",
    "    # Standard normal inverse functions\n",
    "    def g(p):\n",
    "        return stats.norm.ppf(p)\n",
    "    \n",
    "    df['CapitalRequirement'] = (df['LGD'] * stats.norm.cdf(\n",
    "        (1 - df['R'])**-0.5 * g(df['PD_Estimate']) + \n",
    "        (df['R'] / (1 - df['R']))**0.5 * g(0.999)) - \n",
    "        df['PD_Estimate'] * df['LGD']) * \\\n",
    "        (1 - 1.5 * df['b'])**-1 * (1 + (1 - 2.5) * df['b'])\n",
    "    \n",
    "    # Total capital required\n",
    "    total_capital = df['CapitalRequirement'].sum()\n",
    "    total_exposure = df['EAD'].sum()\n",
    "    capital_ratio = total_capital / total_exposure\n",
    "    \n",
    "    print(\"\\nBasel II Capital Calculation Results:\")\n",
    "    print(f\"Total Exposure at Default (EAD): ${total_exposure:,.2f}\")\n",
    "    print(f\"Total Capital Required: ${total_capital:,.2f}\")\n",
    "    print(f\"Capital Ratio: {capital_ratio:.2%}\")\n",
    "    print(\"\\nNote: This is a simplified calculation. Actual Basel II implementation requires more complex modeling.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate Basel II capital\n",
    "df_with_capital = calculate_basel_capital(df, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Business Impact Analysis\n",
    "Quantifying the financial impact:\n",
    "- Fraud prevented vs. missed\n",
    "- Operational costs\n",
    "- ROI calculation\n",
    "- Customer impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Business Impact Analysis\n",
    "def business_impact_analysis(df, model_results, selected_model='Random Forest'):\n",
    "    \"\"\"Analyze the business impact of implementing the fraud detection model\"\"\"\n",
    "    \n",
    "    print(\"\\nBusiness Impact Analysis:\")\n",
    "    \n",
    "    # Get model predictions and optimal threshold\n",
    "    model = model_results[selected_model]['Model']\n",
    "    threshold = model_results[selected_model]['Optimal Threshold']\n",
    "    \n",
    "    # Prepare test set for prediction\n",
    "    X = df.drop(['FraudResult', 'TransactionId', 'TransactionStartTime'], axis=1)\n",
    "    y = df['FraudResult']\n",
    "    \n",
    "    # Convert categorical variables\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if X[col].nunique() > 10:\n",
    "            fraud_rate = y.groupby(X[col]).mean()\n",
    "            counts = y.groupby(X[col]).count()\n",
    "            global_mean = y.mean()\n",
    "            smoothing = 100\n",
    "            X[col] = X[col].map((fraud_rate * counts + global_mean * smoothing) / (counts + smoothing))\n",
    "        else:\n",
    "            X = pd.get_dummies(X, columns=[col], drop_first=True)\n",
    "    \n",
    "    # Scale and select features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    selector = SelectKBest(f_classif, k=N_TOP_FEATURES)\n",
    "    X_scaled = selector.fit_transform(X_scaled, y)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    display(cm)\n",
    "    \n",
    "    # Financial impact metrics\n",
    "    fraud_caught = cm.loc[1, 1]\n",
    "    fraud_missed = cm.loc[1, 0]\n",
    "    false_positives = cm.loc[0, 1]\n",
    "    \n",
    "    avg_fraud_amount = df[df['FraudResult']==1]['Amount'].mean()\n",
    "    avg_transaction_amount = df['Amount'].mean()\n",
    "    \n",
    "    fraud_prevented = fraud_caught * avg_fraud_amount\n",
    "    fraud_loss = fraud_missed * avg_fraud_amount\n",
    "    operational_cost = false_positives * avg_transaction_amount * 0.10  # Assuming 10% of transaction amount as cost\n",
    "    \n",
    "    net_savings = fraud_prevented - fraud_loss - operational_cost\n",
    "    \n",
    "    print(\"\\nFinancial Impact Estimation:\")\n",
    "    print(f\"Fraud Prevented: ${fraud_prevented:,.2f} ({fraud_caught} transactions)\")\n",
    "    print(f\"Fraud Loss (Missed): ${fraud_loss:,.2f} ({fraud_missed} transactions)\")\n",
    "    print(f\"Operational Cost (False Positives): ${operational_cost:,.2f} ({false_positives} transactions)\")\n",
    "    print(f\"Net Savings: ${net_savings:,.2f}\")\n",
    "    \n",
    "    # ROI calculation (simplified)\n",
    "    development_cost = 50000  # Estimated model development cost\n",
    "    implementation_cost = 20000  # Estimated implementation cost\n",
    "    annual_maintenance = 10000  # Estimated annual maintenance\n",
    "    \n",
    "    first_year_roi = (net_savings - development_cost - implementation_cost) / \\\n",
    "                    (development_cost + implementation_cost)\n",
    "    ongoing_roi = (net_savings - annual_maintenance) / annual_maintenance\n",
    "    \n",
    "    print(\"\\nReturn on Investment (ROI):\")\n",
    "    print(f\"First Year ROI: {first_year_roi:.0%}\")\n",
    "    print(f\"Ongoing Annual ROI: {ongoing_roi:.0%}\")\n",
    "    \n",
    "    # Customer impact analysis\n",
    "    customers_affected = df[y_pred == 1]['CustomerId'].nunique()\n",
    "    total_customers = df['CustomerId'].nunique()\n",
    "    \n",
    "    print(\"\\nCustomer Impact:\")\n",
    "    print(f\"Customers Affected by Fraud Alerts: {customers_affected:,} ({customers_affected/total_customers:.1%})\")\n",
    "    \n",
    "    return {\n",
    "        'fraud_prevented': fraud_prevented,\n",
    "        'fraud_loss': fraud_loss,\n",
    "        'operational_cost': operational_cost,\n",
    "        'net_savings': net_savings,\n",
    "        'first_year_roi': first_year_roi,\n",
    "        'ongoing_roi': ongoing_roi\n",
    "    }\n",
    "\n",
    "# Run business impact analysis\n",
    "impact_results = business_impact_analysis(df, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deployment Recommendations\n",
    "Strategic recommendations for production:\n",
    "1. Implementation strategy\n",
    "2. Risk threshold optimization\n",
    "3. Operational integration\n",
    "4. Monitoring framework\n",
    "5. Regulatory compliance\n",
    "6. Expected benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Model Deployment Recommendations\n",
    "def deployment_recommendations(model_results, impact_results):\n",
    "    \"\"\"Provide strategic recommendations for model deployment\"\"\"\n",
    "    \n",
    "    print(\"\\nModel Deployment Recommendations:\")\n",
    "    \n",
    "    # 1. Implementation Strategy\n",
    "    print(\"\\n1. Implementation Strategy:\")\n",
    "    print(\"- Phase 1: Pilot implementation with 10% of transactions to validate performance\")\n",
    "    print(\"- Phase 2: Full deployment with monitoring for concept drift\")\n",
    "    print(\"- Implement as a real-time scoring system integrated with transaction processing\")\n",
    "    \n",
    "    # 2. Risk Threshold Optimization\n",
    "    optimal_threshold = model_results['Random Forest']['Optimal Threshold']\n",
    "    print(f\"\\n2. Risk Threshold Optimization (Current: {optimal_threshold:.2f}):\")\n",
    "    print(\"- Establish threshold tuning process based on changing fraud patterns\")\n",
    "    print(\"- Create multiple thresholds for different customer segments/products\")\n",
    "    \n",
    "    # 3. Operational Integration\n",
    "    print(\"\\n3. Operational Integration:\")\n",
    "    print(\"- Integrate with case management system for fraud analysts\")\n",
    "    print(\"- Implement automated alerts for high-risk transactions\")\n",
    "    print(\"- Create escalation procedures based on risk scores\")\n",
    "    \n",
    "    # 4. Monitoring Framework\n",
    "    print(\"\\n4. Monitoring Framework:\")\n",
    "    print(\"- Track model performance metrics weekly (AUC, precision, recall)\")\n",
    "    print(\"- Monitor feature distributions for data drift\")\n",
    "    print(\"- Establish feedback loop from fraud investigation teams\")\n",
    "    \n",
    "    # 5. Regulatory Compliance\n",
    "    print(\"\\n5. Regulatory Compliance:\")\n",
    "    print(\"- Document model development process for audit purposes\")\n",
    "    print(\"- Validate model meets Basel II requirements for risk quantification\")\n",
    "    print(\"- Implement governance process for model updates\")\n",
    "    \n",
    "    # 6. Expected Benefits\n",
    "    print(\"\\n6. Expected Benefits:\")\n",
    "    print(f\"- Annual fraud prevention: ${impact_results['fraud_prevented']:,.2f}\")\n",
    "    print(f\"- Operational cost: ${impact_results['operational_cost']:,.2f}\")\n",
    "    print(f\"- Net savings: ${impact_results['net_savings']:,.2f}\")\n",
    "    print(f\"- First year ROI: {impact_results['first_year_roi']:.0%}\")\n",
    "    print(f\"- Ongoing ROI: {impact_results['ongoing_roi']:.0%}\")\n",
    "\n",
    "# Provide deployment recommendations\n",
    "deployment_recommendations(model_results, impact_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
